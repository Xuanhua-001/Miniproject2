{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a02285e6",
   "metadata": {
    "id": "a02285e6"
   },
   "source": [
    "# Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdcc5329",
   "metadata": {
    "id": "bdcc5329"
   },
   "source": [
    "Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7",
   "metadata": {
    "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263",
   "metadata": {
    "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\allen\\AppData\\Roaming\\Python\\Python312\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from transformers import RobertaModel, RobertaTokenizer, TrainingArguments, Trainer, DataCollatorWithPadding, RobertaForSequenceClassification\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from datasets import load_dataset, Dataset, ClassLabel\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59d6e377",
   "metadata": {
    "id": "59d6e377"
   },
   "source": [
    "## Load Tokenizer and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21f42747-f551-40a5-a95f-7affb1eba4a3",
   "metadata": {
    "id": "21f42747-f551-40a5-a95f-7affb1eba4a3"
   },
   "outputs": [],
   "source": [
    "base_model = 'roberta-base'\n",
    "\n",
    "dataset = load_dataset('ag_news', split='train')\n",
    "tokenizer = RobertaTokenizer.from_pretrained(base_model)\n",
    "\n",
    "def preprocess(examples):\n",
    "    tokenized = tokenizer(examples['text'], truncation=True, padding=True)\n",
    "    return tokenized\n",
    "\n",
    "tokenized_dataset = dataset.map(preprocess, batched=True,  remove_columns=[\"text\"])\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e07f641-bec0-43a6-8c26-510d7642916a",
   "metadata": {
    "id": "9e07f641-bec0-43a6-8c26-510d7642916a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of labels: 4\n",
      "the labels: ['World', 'Sports', 'Business', 'Sci/Tech']\n"
     ]
    }
   ],
   "source": [
    "# Extract the number of classess and their names\n",
    "num_labels = dataset.features['label'].num_classes\n",
    "class_names = dataset.features[\"label\"].names\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "# Create an id2label mapping\n",
    "# We will need this for our classifier.\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9e24afd",
   "metadata": {
    "id": "c9e24afd"
   },
   "source": [
    "## Load Pre-trained Model\n",
    "Set up config for pretrained model and download it from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "262a8416-a59c-4ea1-95d9-0b1f81d6094c",
   "metadata": {
    "id": "262a8416-a59c-4ea1-95d9-0b1f81d6094c"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    base_model,\n",
    "    num_labels=num_labels, \n",
    "    id2label=id2label,\n",
    "    label2id={v: k for k, v in id2label.items()})\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f265839d-a088-4693-8474-862641de11ed",
   "metadata": {
    "id": "f265839d-a088-4693-8474-862641de11ed"
   },
   "source": [
    "## Anything from here on can be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7413430-be57-482b-856e-36bd4ba799df",
   "metadata": {
    "id": "e7413430-be57-482b-856e-36bd4ba799df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 110000\n",
      "Validation set size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Split the original training set, increse the size of test size\n",
    "split_datasets = tokenized_dataset.train_test_split(test_size=10000, seed=42)\n",
    "train_dataset = split_datasets['train']\n",
    "eval_dataset = split_datasets['test']\n",
    "print(f\"Train set size: {len(train_dataset)}\")\n",
    "print(f\"Validation set size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "652452e3",
   "metadata": {
    "id": "652452e3"
   },
   "source": [
    "## Setup LoRA Config\n",
    "Setup PEFT config and get peft model for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bd0ca0ea-86b8-47f7-8cbf-83da25685876",
   "metadata": {
    "id": "bd0ca0ea-86b8-47f7-8cbf-83da25685876"
   },
   "outputs": [],
   "source": [
    "# PEFT Config\n",
    "peft_config = LoraConfig(\n",
    "    r=6,\n",
    "    lora_alpha=16,\n",
    "    lora_dropout=0.2,\n",
    "    bias = 'lora_only',\n",
    "    target_modules = ['query','value','out_proj','key'],\n",
    "    task_type=\"SEQ_CLS\",\n",
    "    modules_to_save=[\"classifier\"],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4ab30576-5570-4844-994d-a320f1980bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RobertaForSequenceClassification(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): RobertaClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    base_model,\n",
    "    num_labels=num_labels, \n",
    "    id2label=id2label,\n",
    "    label2id={v: k for k, v in id2label.items()})\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6ec2739d-76b6-4fde-91c2-0fc49e1884b0",
   "metadata": {
    "id": "6ec2739d-76b6-4fde-91c2-0fc49e1884b0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PeftModelForSequenceClassification(\n",
       "  (base_model): LoraModel(\n",
       "    (model): RobertaForSequenceClassification(\n",
       "      (roberta): RobertaModel(\n",
       "        (embeddings): RobertaEmbeddings(\n",
       "          (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "          (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "          (token_type_embeddings): Embedding(1, 768)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder): RobertaEncoder(\n",
       "          (layer): ModuleList(\n",
       "            (0-11): 12 x RobertaLayer(\n",
       "              (attention): RobertaAttention(\n",
       "                (self): RobertaSdpaSelfAttention(\n",
       "                  (query): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=6, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (key): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=6, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (value): lora.Linear(\n",
       "                    (base_layer): Linear(in_features=768, out_features=768, bias=True)\n",
       "                    (lora_dropout): ModuleDict(\n",
       "                      (default): Dropout(p=0.2, inplace=False)\n",
       "                    )\n",
       "                    (lora_A): ModuleDict(\n",
       "                      (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "                    )\n",
       "                    (lora_B): ModuleDict(\n",
       "                      (default): Linear(in_features=6, out_features=768, bias=False)\n",
       "                    )\n",
       "                    (lora_embedding_A): ParameterDict()\n",
       "                    (lora_embedding_B): ParameterDict()\n",
       "                    (lora_magnitude_vector): ModuleDict()\n",
       "                  )\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "                (output): RobertaSelfOutput(\n",
       "                  (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                  (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                  (dropout): Dropout(p=0.1, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (intermediate): RobertaIntermediate(\n",
       "                (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "                (intermediate_act_fn): GELUActivation()\n",
       "              )\n",
       "              (output): RobertaOutput(\n",
       "                (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (classifier): ModulesToSaveWrapper(\n",
       "        (original_module): RobertaClassificationHead(\n",
       "          (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): RobertaClassificationHead(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
       "          )\n",
       "        )\n",
       "        (out_proj): lora.Linear(\n",
       "          (base_layer): Linear(in_features=768, out_features=4, bias=True)\n",
       "          (lora_dropout): ModuleDict(\n",
       "            (default): Dropout(p=0.2, inplace=False)\n",
       "          )\n",
       "          (lora_A): ModuleDict(\n",
       "            (default): Linear(in_features=768, out_features=6, bias=False)\n",
       "          )\n",
       "          (lora_B): ModuleDict(\n",
       "            (default): Linear(in_features=6, out_features=4, bias=False)\n",
       "          )\n",
       "          (lora_embedding_A): ParameterDict()\n",
       "          (lora_embedding_B): ParameterDict()\n",
       "          (lora_magnitude_vector): ModuleDict()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a769f54e-05ad-4e3c-aae8-d00d1d9dfb2f",
   "metadata": {
    "id": "a769f54e-05ad-4e3c-aae8-d00d1d9dfb2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trainable parameters:\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.0.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.1.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.2.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.3.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.4.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.5.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.6.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.7.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.8.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.9.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.10.attention.self.value.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.query.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.key.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.key.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.key.lora_B.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.base_layer.bias\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_A.default.weight\n",
      "base_model.model.roberta.encoder.layer.11.attention.self.value.lora_B.default.weight\n",
      "base_model.model.classifier.modules_to_save.default.dense.weight\n",
      "base_model.model.classifier.modules_to_save.default.dense.bias\n",
      "base_model.model.classifier.modules_to_save.default.out_proj.weight\n",
      "base_model.model.classifier.modules_to_save.default.out_proj.bias\n",
      "base_model.model.classifier.out_proj.lora_A.default.weight\n",
      "base_model.model.classifier.out_proj.lora_B.default.weight\n"
     ]
    }
   ],
   "source": [
    "print(\"Trainable parameters:\")\n",
    "for name, param in peft_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "da45f85c-b016-4c49-8808-6eafa7cb5d1b",
   "metadata": {
    "id": "da45f85c-b016-4c49-8808-6eafa7cb5d1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PEFT Model\n",
      "trainable params: 957,724 || all params: 125,578,784 || trainable%: 0.7626\n"
     ]
    }
   ],
   "source": [
    "print('PEFT Model')\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12284b58",
   "metadata": {
    "id": "12284b58"
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1",
   "metadata": {
    "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1"
   },
   "outputs": [],
   "source": [
    "# To track evaluation accuracy during training\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels, preds)\n",
    "    return {\n",
    "        'accuracy': accuracy\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "10dd372a-3c98-4e10-98a7-a10bd48c76ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup Training args\n",
    "output_dir = \"results\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=output_dir,\n",
    "    report_to=None,\n",
    "    eval_strategy='steps',\n",
    "    \n",
    "    logging_steps=100,\n",
    "    learning_rate=3e-5,\n",
    "    num_train_epochs=1,\n",
    "    max_steps=3600,\n",
    "    \n",
    "    use_cpu=False,\n",
    "    dataloader_num_workers=4,\n",
    "    \n",
    "    per_device_train_batch_size=24,\n",
    "    per_device_eval_batch_size=96,\n",
    "    \n",
    "    optim=\"adamw_torch\",\n",
    "    gradient_checkpointing=False,\n",
    "    gradient_checkpointing_kwargs={'use_reentrant':True},\n",
    "    label_names=[\"labels\"],\n",
    "\n",
    "    lr_scheduler_type='polynomial',\n",
    "    warmup_ratio=0.2,\n",
    "    weight_decay=0.05,\n",
    "    fp16=True,\n",
    "\n",
    "    label_smoothing_factor=0.1,\n",
    "\n",
    ")\n",
    "model.classifier.dropout.p = 0.3\n",
    "def get_trainer(model):\n",
    "      return  Trainer(\n",
    "          model=model,\n",
    "          args=training_args,\n",
    "          compute_metrics=compute_metrics,\n",
    "          train_dataset=train_dataset,\n",
    "          eval_dataset=eval_dataset,\n",
    "          data_collator=data_collator,\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f2a8ba81-a2ce-43fe-87f8-2cdeaf069812",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModulesToSaveWrapper(\n",
      "  (original_module): RobertaClassificationHead(\n",
      "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "    (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
      "  )\n",
      "  (modules_to_save): ModuleDict(\n",
      "    (default): RobertaClassificationHead(\n",
      "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
      "      (dropout): Dropout(p=0.3, inplace=False)\n",
      "      (out_proj): Linear(in_features=768, out_features=4, bias=True)\n",
      "    )\n",
      "  )\n",
      "  (out_proj): lora.Linear(\n",
      "    (base_layer): Linear(in_features=768, out_features=4, bias=True)\n",
      "    (lora_dropout): ModuleDict(\n",
      "      (default): Dropout(p=0.2, inplace=False)\n",
      "    )\n",
      "    (lora_A): ModuleDict(\n",
      "      (default): Linear(in_features=768, out_features=6, bias=False)\n",
      "    )\n",
      "    (lora_B): ModuleDict(\n",
      "      (default): Linear(in_features=6, out_features=4, bias=False)\n",
      "    )\n",
      "    (lora_embedding_A): ParameterDict()\n",
      "    (lora_embedding_B): ParameterDict()\n",
      "    (lora_magnitude_vector): ModuleDict()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model.classifier)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b848278",
   "metadata": {
    "id": "9b848278"
   },
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "302dbc90-5a72-4e95-a379-3eeea271a4a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3600' max='3600' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3600/3600 49:03, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.408200</td>\n",
       "      <td>1.395404</td>\n",
       "      <td>0.240700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>1.394000</td>\n",
       "      <td>1.384620</td>\n",
       "      <td>0.240700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>1.381000</td>\n",
       "      <td>1.372619</td>\n",
       "      <td>0.335000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>1.364800</td>\n",
       "      <td>1.328289</td>\n",
       "      <td>0.786000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>1.090000</td>\n",
       "      <td>0.646069</td>\n",
       "      <td>0.876100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.624100</td>\n",
       "      <td>0.587570</td>\n",
       "      <td>0.885700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.580100</td>\n",
       "      <td>0.577178</td>\n",
       "      <td>0.894200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>0.560700</td>\n",
       "      <td>0.571622</td>\n",
       "      <td>0.898500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>0.585900</td>\n",
       "      <td>0.558333</td>\n",
       "      <td>0.903300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>0.554600</td>\n",
       "      <td>0.560675</td>\n",
       "      <td>0.902100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>0.562500</td>\n",
       "      <td>0.556611</td>\n",
       "      <td>0.903200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>0.547400</td>\n",
       "      <td>0.553895</td>\n",
       "      <td>0.905200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>0.545900</td>\n",
       "      <td>0.552861</td>\n",
       "      <td>0.905600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>0.550700</td>\n",
       "      <td>0.552766</td>\n",
       "      <td>0.905800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>0.559000</td>\n",
       "      <td>0.550322</td>\n",
       "      <td>0.906700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>0.562700</td>\n",
       "      <td>0.547324</td>\n",
       "      <td>0.908700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>0.546200</td>\n",
       "      <td>0.547321</td>\n",
       "      <td>0.908600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>0.549300</td>\n",
       "      <td>0.547296</td>\n",
       "      <td>0.906800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>0.554900</td>\n",
       "      <td>0.544408</td>\n",
       "      <td>0.908900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>0.542400</td>\n",
       "      <td>0.543448</td>\n",
       "      <td>0.910500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>0.546400</td>\n",
       "      <td>0.543479</td>\n",
       "      <td>0.910300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>0.548500</td>\n",
       "      <td>0.543017</td>\n",
       "      <td>0.907100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.540400</td>\n",
       "      <td>0.540937</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.541856</td>\n",
       "      <td>0.909800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.538900</td>\n",
       "      <td>0.541595</td>\n",
       "      <td>0.910300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.550300</td>\n",
       "      <td>0.537338</td>\n",
       "      <td>0.911800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.543200</td>\n",
       "      <td>0.538275</td>\n",
       "      <td>0.911100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.550100</td>\n",
       "      <td>0.537024</td>\n",
       "      <td>0.910200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.542400</td>\n",
       "      <td>0.538583</td>\n",
       "      <td>0.910900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.539300</td>\n",
       "      <td>0.537774</td>\n",
       "      <td>0.911800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.546500</td>\n",
       "      <td>0.536074</td>\n",
       "      <td>0.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.540900</td>\n",
       "      <td>0.535957</td>\n",
       "      <td>0.911600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.534400</td>\n",
       "      <td>0.535560</td>\n",
       "      <td>0.911800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.527600</td>\n",
       "      <td>0.535829</td>\n",
       "      <td>0.912400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.531800</td>\n",
       "      <td>0.536078</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.529300</td>\n",
       "      <td>0.536249</td>\n",
       "      <td>0.912100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "peft_lora_finetuning_trainer = get_trainer(peft_model)\n",
    "\n",
    "result = peft_lora_finetuning_trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5183be7e-514f-4e64-a6f4-314a827e6be5",
   "metadata": {
    "id": "5183be7e-514f-4e64-a6f4-314a827e6be5"
   },
   "source": [
    "## Evaluate Finetuned Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038198cf-0953-47e7-bd47-b073d05f8378",
   "metadata": {
    "id": "038198cf-0953-47e7-bd47-b073d05f8378"
   },
   "source": [
    "### Performing Inference on Custom Input\n",
    "Uncomment following functions for running inference on custom inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f88ad420-3f46-4eff-9d71-0ce388163062",
   "metadata": {
    "id": "f88ad420-3f46-4eff-9d71-0ce388163062"
   },
   "outputs": [],
   "source": [
    "def classify(model, tokenizer, text):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\").to(device)\n",
    "    output = model(**inputs)\n",
    "    prediction = output.logits.argmax(dim=-1).item()\n",
    "\n",
    "    print(f'\\n Class: {prediction}, Label: {id2label[prediction]}, Text: {text}')\n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fc52bb94-5e13-4943-9225-a6d7fd053579",
   "metadata": {
    "id": "fc52bb94-5e13-4943-9225-a6d7fd053579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Class: 1, Label: Sports, Text: Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\n",
      "\n",
      " Class: 2, Label: Business, Text: Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindlinand of ultra-cynics, are seeing green again.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Business'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classify( peft_model, tokenizer, \"Kederis proclaims innocence Olympic champion Kostas Kederis today left hospital ahead of his date with IOC inquisitors claiming his ...\")\n",
    "classify( peft_model, tokenizer, \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\band of ultra-cynics, are seeing green again.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68a3e276-bf8c-4403-8a48-5ef19f2beccf",
   "metadata": {
    "id": "68a3e276-bf8c-4403-8a48-5ef19f2beccf"
   },
   "source": [
    "### Run Inference on eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5",
   "metadata": {
    "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(inference_model, dataset, labelled=True, batch_size=8, data_collator=None):\n",
    "    \"\"\"\n",
    "    Evaluate a PEFT model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        inference_model: The model to evaluate.\n",
    "        dataset: The dataset (Hugging Face Dataset) to run inference on.\n",
    "        labelled (bool): If True, the dataset includes labels and metrics will be computed.\n",
    "                         If False, only predictions will be returned.\n",
    "        batch_size (int): Batch size for inference.\n",
    "        data_collator: Function to collate batches. If None, the default collate_fn is used.\n",
    "\n",
    "    Returns:\n",
    "        If labelled is True, returns a tuple (metrics, predictions)\n",
    "        If labelled is False, returns the predictions.\n",
    "    \"\"\"\n",
    "    # Create the DataLoader\n",
    "    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inference_model.to(device)\n",
    "    inference_model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    if labelled:\n",
    "        metric = evaluate.load('accuracy')\n",
    "\n",
    "    # Loop over the DataLoader\n",
    "    for batch in tqdm(eval_dataloader):\n",
    "        # Move each tensor in the batch to the device\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = inference_model(**batch)\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        all_predictions.append(predictions.cpu())\n",
    "\n",
    "        if labelled:\n",
    "            # Expecting that labels are provided under the \"labels\" key.\n",
    "            references = batch[\"labels\"]\n",
    "            metric.add_batch(\n",
    "                predictions=predictions.cpu().numpy(),\n",
    "                references=references.cpu().numpy()\n",
    "            )\n",
    "\n",
    "    # Concatenate predictions from all batches\n",
    "    all_predictions = torch.cat(all_predictions, dim=0)\n",
    "\n",
    "    if labelled:\n",
    "        eval_metric = metric.compute()\n",
    "        print(\"Evaluation Metric:\", eval_metric)\n",
    "        return eval_metric, all_predictions\n",
    "    else:\n",
    "        return all_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84d72ba3-ecb2-48b8-83a6-a43d2ef4f3ad",
   "metadata": {},
   "source": [
    "### load the last model and check the last model accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95251490-65d9-46eb-8dd0-6bffd21a1104",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "peft_config = PeftConfig.from_pretrained(\"results/checkpoint-3600\")\n",
    "base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    peft_config.base_model_name_or_path,\n",
    "    num_labels=4\n",
    ")\n",
    "peft_model = PeftModel.from_pretrained(base_model, \"results/checkpoint-3600\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "809635a6-a2c7-4d09-8d60-ababd1815003",
   "metadata": {
    "id": "809635a6-a2c7-4d09-8d60-ababd1815003"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [00:56<00:00, 22.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metric: {'accuracy': 0.911}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Check evaluation accuracy\n",
    "\n",
    "_, _ = evaluate_model(peft_model, eval_dataset, True, 8, data_collator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "187dd551-f1b1-480c-bea7-fa8b1386948f",
   "metadata": {
    "id": "kMJgvV1ZnVhd"
   },
   "source": [
    "### draw graph(with help from gpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "5365dfa9-ff2b-4216-9a89-e8b482f912c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import TrainerState\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "with open(\"results/checkpoint-3600/trainer_state.json\") as f:\n",
    "    state = json.load(f)\n",
    "\n",
    "steps = [log[\"step\"] for log in state[\"log_history\"] if \"loss\" in log]\n",
    "loss = [log[\"loss\"] for log in state[\"log_history\"] if \"loss\" in log]\n",
    "val_loss = [log[\"eval_loss\"] for log in state[\"log_history\"] if \"eval_loss\" in log]\n",
    "acc = [log[\"eval_accuracy\"] for log in state[\"log_history\"] if \"eval_accuracy\" in log]\n",
    "\n",
    "plt.plot(steps, loss, label=\"Training Loss\")\n",
    "plt.plot(steps, val_loss, label=\"Validation Loss\")\n",
    "plt.plot(steps, acc, label=\"Accuracy\")\n",
    "plt.xlabel(\"Steps\")\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203",
   "metadata": {
    "id": "75f39087-f2bb-49d3-9fe1-0d812fb30203"
   },
   "source": [
    "### Run Inference on unlabelled dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2af62541-2c33-4f16-bb1c-cc969c715cd7",
   "metadata": {
    "id": "2af62541-2c33-4f16-bb1c-cc969c715cd7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "882cdf3c68eb45c3a75eb327f1bf2d95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 8000\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Load your unlabelled data\n",
    "unlabelled_dataset = pd.read_pickle(\"test_unlabelled.pkl\")\n",
    "test_dataset = unlabelled_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "unlabelled_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e60991d3-38b1-4657-8854-408ce66f6b84",
   "metadata": {
    "id": "e60991d3-38b1-4657-8854-408ce66f6b84"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 1000/1000 [00:34<00:00, 28.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inference complete. Predictions saved to inference_output.csv\n"
     ]
    }
   ],
   "source": [
    "# Run inference and save predictions\n",
    "preds = evaluate_model(peft_model, test_dataset, False, 8, data_collator)\n",
    "df_output = pd.DataFrame({\n",
    "    'ID': range(len(preds)),\n",
    "    'Label': preds.numpy()  # or preds.tolist()\n",
    "})\n",
    "df_output.to_csv(os.path.join(output_dir,\"inference_output.csv\"), index=False)\n",
    "print(\"Inference complete. Predictions saved to inference_output.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97e9ccbd-fc02-42f9-9532-afd53bdb03b7",
   "metadata": {},
   "source": [
    "### Try using Ensemble to increase the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b025ceb6-5d99-4f1f-8114-88e5922c5ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_logits(model, test_dataset, batch_size, data_collator):\n",
    "    dataloader = DataLoader(test_dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "    model.eval()\n",
    "    model.to(\"cuda\")\n",
    "    \n",
    "    all_logits = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            batch = {k: v.to(\"cuda\") for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            logits = outputs.logits.detach().cpu()\n",
    "            all_logits.append(logits)\n",
    "    \n",
    "    return torch.cat(all_logits, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ec3ca661-e980-4072-bbe4-8af92a294591",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "checkpoint_paths = [\n",
    "    \"results/checkpoint-1000\",\n",
    "    \"results/checkpoint-1500\",\n",
    "    \"results/checkpoint-2000\",\n",
    "    \"results/checkpoint-3000\",\n",
    "    \"results/checkpoint-2500\",\n",
    "    \"results/checkpoint-3500\",\n",
    "    \"results/checkpoint-3600\",\n",
    "]\n",
    "\n",
    "logits_list = []\n",
    "\n",
    "for path in checkpoint_paths:\n",
    "    peft_config = PeftConfig.from_pretrained(path)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        peft_config.base_model_name_or_path,\n",
    "        num_labels=4\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(base_model, path)\n",
    "    \n",
    "    logits = evaluate_logits(model, eval_dataset, 8, data_collator)\n",
    "    logits_list.append(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8485df2-0a57-4901-b9b4-5ad4130d3e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "def evaluate_from_logits(logits, dataset):\n",
    "    preds = torch.argmax(logits, dim=-1).numpy()\n",
    "    labels = np.array(dataset[\"labels\"])\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    print(f\"✅ Ensemble Accuracy: {acc:.4f}\")\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cecab05-0431-4746-9558-91bd69989d1c",
   "metadata": {},
   "source": [
    "### run Ensemble on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "da392ac7-88ea-4d1d-9d26-5c52aec18702",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ensemble Accuracy: 0.9105\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9105"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_logits = sum(logits_list) / len(logits_list)\n",
    "evaluate_from_logits(ensemble_logits, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "212735af-1ea2-49e6-955a-3e89aec3ebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from peft import PeftModel, PeftConfig\n",
    "\n",
    "checkpoint_paths = [\n",
    "    \"results/checkpoint-1000\",\n",
    "    \"results/checkpoint-1500\",\n",
    "    \"results/checkpoint-2000\",\n",
    "    \"results/checkpoint-3000\",\n",
    "    \"results/checkpoint-2500\",\n",
    "    \"results/checkpoint-3500\",\n",
    "    \"results/checkpoint-3600\",\n",
    "]\n",
    "\n",
    "logits_list = []\n",
    "\n",
    "for path in checkpoint_paths:\n",
    "    peft_config = PeftConfig.from_pretrained(path)\n",
    "    base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "        peft_config.base_model_name_or_path,\n",
    "        num_labels=4\n",
    "    )\n",
    "    model = PeftModel.from_pretrained(base_model, path)\n",
    "    \n",
    "    logits = evaluate_logits(model, test_dataset, 8, data_collator)\n",
    "    logits_list.append(logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "35426812-cf0d-4d0d-8a16-738e2fde813e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Ensemble predictions saved.\n"
     ]
    }
   ],
   "source": [
    "# find average\n",
    "ensemble_logits = sum(logits_list) / len(logits_list)\n",
    "\n",
    "# gget final prediction lable\n",
    "final_preds = torch.argmax(ensemble_logits, dim=-1).numpy()\n",
    "\n",
    "# save to file\n",
    "df_output = pd.DataFrame({\n",
    "    'ID': range(len(final_preds)),\n",
    "    'Label': final_preds\n",
    "})\n",
    "df_output.to_csv(os.path.join(output_dir, \"inference_output_ensemble.csv\"), index=False)\n",
    "\n",
    "print(\"✅ Ensemble predictions saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049aba9-69eb-4f7b-84d5-247ba42b3117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
